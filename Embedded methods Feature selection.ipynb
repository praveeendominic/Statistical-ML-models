{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a7e0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "224c4544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "ID                                                             \n",
       "1      2     23                 0.0                      0.0   \n",
       "3      2     34                 0.0                      0.0   \n",
       "4      2     23                 0.0                      0.0   \n",
       "8      2     37                 0.0                    195.0   \n",
       "10     2     39                 0.0                      0.0   \n",
       "\n",
       "    imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "ID                                                                              \n",
       "1                       0.0                      0.0                      0.0   \n",
       "3                       0.0                      0.0                      0.0   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "8                     195.0                      0.0                      0.0   \n",
       "10                      0.0                      0.0                      0.0   \n",
       "\n",
       "    imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "ID                                                                       ...   \n",
       "1                         0                        0                0.0  ...   \n",
       "3                         0                        0                0.0  ...   \n",
       "4                         0                        0                0.0  ...   \n",
       "8                         0                        0                0.0  ...   \n",
       "10                        0                        0                0.0  ...   \n",
       "\n",
       "    saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "ID                                                                             \n",
       "1                         0                        0                       0   \n",
       "3                         0                        0                       0   \n",
       "4                         0                        0                       0   \n",
       "8                         0                        0                       0   \n",
       "10                        0                        0                       0   \n",
       "\n",
       "    saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "ID                                                                             \n",
       "1                        0                      0.0                      0.0   \n",
       "3                        0                      0.0                      0.0   \n",
       "4                        0                      0.0                      0.0   \n",
       "8                        0                      0.0                      0.0   \n",
       "10                       0                      0.0                      0.0   \n",
       "\n",
       "    saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "ID                                                                         \n",
       "1                      0.0                     0.0   39205.170000       0  \n",
       "3                      0.0                     0.0   49278.030000       0  \n",
       "4                      0.0                     0.0   67333.770000       0  \n",
       "8                      0.0                     0.0   64007.970000       0  \n",
       "10                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('santander.csv',index_col='ID',nrows=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4fef91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 1 to 1981\n",
      "Columns: 370 entries, var3 to TARGET\n",
      "dtypes: float64(71), int64(299)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d79b2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Selection using Embedded techniques\n",
    "# -Feature Importance rf\n",
    "# -PCA and LDA\n",
    "# -Ridge & Lasso Regression\n",
    "# -RFE Recurive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "306b83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=df.iloc[:,:-1],df.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a26fdfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=-10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=-10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, n_jobs=-10)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=10,n_jobs=-10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3b17f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.53606026e-04, 2.24319314e-01, 4.93461633e-03, 6.28443937e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.15601323e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.80192077e-03, 3.69214352e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.72515505e-03, 0.00000000e+00,\n",
       "       2.83483162e-03, 2.71748836e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.49180678e-03,\n",
       "       2.96483679e-03, 0.00000000e+00, 0.00000000e+00, 4.44115470e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.89267751e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.65681521e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.53949995e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.90575425e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.22057735e-03, 0.00000000e+00, 2.80548579e-03,\n",
       "       8.35534933e-03, 0.00000000e+00, 9.61403499e-05, 1.28029758e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.97466832e-03, 3.04281326e-04, 1.37383504e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.93670116e-04, 2.31721950e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.86097417e-05,\n",
       "       0.00000000e+00, 1.33660423e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.43385545e-03,\n",
       "       0.00000000e+00, 3.48325859e-03, 3.22170900e-03, 8.15458315e-04,\n",
       "       0.00000000e+00, 2.14390688e-03, 1.06609681e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.39666518e-03, 6.27803054e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.61957665e-05,\n",
       "       2.46730817e-03, 0.00000000e+00, 0.00000000e+00, 3.61619819e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.00807699e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.09546478e-04, 3.48783547e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.89145614e-06,\n",
       "       2.87552460e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.34038874e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.66229058e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.91393792e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.77385390e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.41015801e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.18178882e-03, 1.98790090e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.37270894e-05, 2.20452073e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.78099185e-03, 1.42064096e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.33210581e-05, 4.94104889e-03, 3.76975238e-03,\n",
       "       3.30826241e-02, 1.91329665e-02, 1.64502229e-05, 7.88092185e-03,\n",
       "       1.83575498e-02, 1.15189679e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.34910886e-02, 0.00000000e+00, 2.63855342e-04,\n",
       "       6.59603656e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.34237602e-04, 6.81157788e-03, 1.90476548e-03,\n",
       "       8.14958062e-03, 0.00000000e+00, 7.29778260e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.61486923e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.58716321e-03,\n",
       "       1.18548718e-02, 2.35454446e-03, 1.55998168e-02, 0.00000000e+00,\n",
       "       1.51798455e-02, 2.97407493e-02, 1.18180541e-03, 3.08438487e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.44115470e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.17379388e-05, 0.00000000e+00, 8.49103498e-05, 0.00000000e+00,\n",
       "       1.01674787e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.07175489e-01])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cc6d42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_imp=pd.Series(rf.feature_importances_,index=df.columns[:-1]).sort_values(ascending=False)[:30]\n",
    "feature_imp.plot(kind='barh',color='teal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbdb2a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var3', 'var15', 'imp_ent_var16_ult1', 'imp_op_var39_comer_ult1',\n",
       "       'imp_op_var39_comer_ult3', 'imp_op_var40_comer_ult1',\n",
       "       'imp_op_var40_comer_ult3', 'imp_op_var40_efect_ult1',\n",
       "       'imp_op_var40_efect_ult3', 'imp_op_var40_ult1',\n",
       "       ...\n",
       "       'saldo_medio_var29_ult3', 'saldo_medio_var33_hace2',\n",
       "       'saldo_medio_var33_hace3', 'saldo_medio_var33_ult1',\n",
       "       'saldo_medio_var33_ult3', 'saldo_medio_var44_hace2',\n",
       "       'saldo_medio_var44_hace3', 'saldo_medio_var44_ult1',\n",
       "       'saldo_medio_var44_ult3', 'var38'],\n",
       "      dtype='object', length=369)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de9b3c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var38', 'var15', 'saldo_var30', 'num_var22_ult1',\n",
       "       'saldo_medio_var5_ult3', 'saldo_medio_var5_hace3', 'saldo_var5',\n",
       "       'num_meses_var39_vig_ult3', 'saldo_var42', 'num_var22_ult3',\n",
       "       'num_meses_var5_ult3', 'num_var45_ult3', 'saldo_medio_var5_hace2',\n",
       "       'num_var5', 'num_var45_hace3', 'num_op_var39_ult3', 'ind_var39_0',\n",
       "       'num_op_var41_efect_ult3', 'num_med_var45_ult3',\n",
       "       'num_op_var39_efect_ult3', 'num_op_var41_comer_ult3', 'var36',\n",
       "       'num_op_var39_comer_ult3', 'num_var30', 'num_var22_hace2',\n",
       "       'imp_ent_var16_ult1', 'imp_op_var41_comer_ult1',\n",
       "       'saldo_medio_var8_ult3', 'ind_var8_0', 'imp_var43_emit_ult1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.index #Top 30 features based on their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f6bf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using PCA, LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97a13d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "715a5dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(n_components=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(n_components=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LDA\n",
    "lda=LinearDiscriminantAnalysis(n_components=df.TARGET.nunique()-1)\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19d0f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda=lda.transform(X_train)\n",
    "X_test_lda=lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92d75bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LinearDiscriminantAnalysis in module sklearn.discriminant_analysis object:\n",
      "\n",
      "class LinearDiscriminantAnalysis(sklearn.base._ClassNamePrefixFeaturesOutMixin, sklearn.linear_model._base.LinearClassifierMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001, covariance_estimator=None)\n",
      " |  \n",
      " |  Linear Discriminant Analysis.\n",
      " |  \n",
      " |  A classifier with a linear decision boundary, generated by fitting class\n",
      " |  conditional densities to the data and using Bayes' rule.\n",
      " |  \n",
      " |  The model fits a Gaussian density to each class, assuming that all classes\n",
      " |  share the same covariance matrix.\n",
      " |  \n",
      " |  The fitted model can also be used to reduce the dimensionality of the input\n",
      " |  by projecting it to the most discriminative directions, using the\n",
      " |  `transform` method.\n",
      " |  \n",
      " |  .. versionadded:: 0.17\n",
      " |     *LinearDiscriminantAnalysis*.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <lda_qda>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  solver : {'svd', 'lsqr', 'eigen'}, default='svd'\n",
      " |      Solver to use, possible values:\n",
      " |        - 'svd': Singular value decomposition (default).\n",
      " |          Does not compute the covariance matrix, therefore this solver is\n",
      " |          recommended for data with a large number of features.\n",
      " |        - 'lsqr': Least squares solution.\n",
      " |          Can be combined with shrinkage or custom covariance estimator.\n",
      " |        - 'eigen': Eigenvalue decomposition.\n",
      " |          Can be combined with shrinkage or custom covariance estimator.\n",
      " |  \n",
      " |  shrinkage : 'auto' or float, default=None\n",
      " |      Shrinkage parameter, possible values:\n",
      " |        - None: no shrinkage (default).\n",
      " |        - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\n",
      " |        - float between 0 and 1: fixed shrinkage parameter.\n",
      " |  \n",
      " |      This should be left to None if `covariance_estimator` is used.\n",
      " |      Note that shrinkage works only with 'lsqr' and 'eigen' solvers.\n",
      " |  \n",
      " |  priors : array-like of shape (n_classes,), default=None\n",
      " |      The class prior probabilities. By default, the class proportions are\n",
      " |      inferred from the training data.\n",
      " |  \n",
      " |  n_components : int, default=None\n",
      " |      Number of components (<= min(n_classes - 1, n_features)) for\n",
      " |      dimensionality reduction. If None, will be set to\n",
      " |      min(n_classes - 1, n_features). This parameter only affects the\n",
      " |      `transform` method.\n",
      " |  \n",
      " |  store_covariance : bool, default=False\n",
      " |      If True, explicitly compute the weighted within-class covariance\n",
      " |      matrix when solver is 'svd'. The matrix is always computed\n",
      " |      and stored for the other solvers.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  tol : float, default=1.0e-4\n",
      " |      Absolute threshold for a singular value of X to be considered\n",
      " |      significant, used to estimate the rank of X. Dimensions whose\n",
      " |      singular values are non-significant are discarded. Only used if\n",
      " |      solver is 'svd'.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  covariance_estimator : covariance estimator, default=None\n",
      " |      If not None, `covariance_estimator` is used to estimate\n",
      " |      the covariance matrices instead of relying on the empirical\n",
      " |      covariance estimator (with potential shrinkage).\n",
      " |      The object should have a fit method and a ``covariance_`` attribute\n",
      " |      like the estimators in :mod:`sklearn.covariance`.\n",
      " |      if None the shrinkage parameter drives the estimate.\n",
      " |  \n",
      " |      This should be left to None if `shrinkage` is used.\n",
      " |      Note that `covariance_estimator` works only with 'lsqr' and 'eigen'\n",
      " |      solvers.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_classes, n_features)\n",
      " |      Weight vector(s).\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes,)\n",
      " |      Intercept term.\n",
      " |  \n",
      " |  covariance_ : array-like of shape (n_features, n_features)\n",
      " |      Weighted within-class covariance matrix. It corresponds to\n",
      " |      `sum_k prior_k * C_k` where `C_k` is the covariance matrix of the\n",
      " |      samples in class `k`. The `C_k` are estimated using the (potentially\n",
      " |      shrunk) biased estimator of covariance. If solver is 'svd', only\n",
      " |      exists when `store_covariance` is True.\n",
      " |  \n",
      " |  explained_variance_ratio_ : ndarray of shape (n_components,)\n",
      " |      Percentage of variance explained by each of the selected components.\n",
      " |      If ``n_components`` is not set then all components are stored and the\n",
      " |      sum of explained variances is equal to 1.0. Only available when eigen\n",
      " |      or svd solver is used.\n",
      " |  \n",
      " |  means_ : array-like of shape (n_classes, n_features)\n",
      " |      Class-wise means.\n",
      " |  \n",
      " |  priors_ : array-like of shape (n_classes,)\n",
      " |      Class priors (sum to 1).\n",
      " |  \n",
      " |  scalings_ : array-like of shape (rank, n_classes - 1)\n",
      " |      Scaling of the features in the space spanned by the class centroids.\n",
      " |      Only available for 'svd' and 'eigen' solvers.\n",
      " |  \n",
      " |  xbar_ : array-like of shape (n_features,)\n",
      " |      Overall mean. Only present if solver is 'svd'.\n",
      " |  \n",
      " |  classes_ : array-like of shape (n_classes,)\n",
      " |      Unique class labels.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  QuadraticDiscriminantAnalysis : Quadratic Discriminant Analysis.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> clf = LinearDiscriminantAnalysis()\n",
      " |  >>> clf.fit(X, y)\n",
      " |  LinearDiscriminantAnalysis()\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearDiscriminantAnalysis\n",
      " |      sklearn.base._ClassNamePrefixFeaturesOutMixin\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001, covariance_estimator=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Apply decision function to an array of samples.\n",
      " |      \n",
      " |      The decision function is equal (up to a constant factor) to the\n",
      " |      log-posterior of the model, i.e. `log p(y = k | x)`. In a binary\n",
      " |      classification setting this instead corresponds to the difference\n",
      " |      `log p(y = 1 | x) - log p(y = 0 | x)`. See :ref:`lda_qda_math`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Array of samples (test vectors).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Decision function values related to each class, per sample.\n",
      " |          In the two-class case, the shape is (n_samples,), giving the\n",
      " |          log likelihood ratio of the positive class.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the Linear Discriminant Analysis model.\n",
      " |      \n",
      " |         .. versionchanged:: 0.19\n",
      " |            *store_covariance* has been moved to main constructor.\n",
      " |      \n",
      " |         .. versionchanged:: 0.19\n",
      " |            *tol* has been moved to main constructor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Estimate log probability.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : ndarray of shape (n_samples, n_classes)\n",
      " |          Estimated log probabilities.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Estimate probability.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : ndarray of shape (n_samples, n_classes)\n",
      " |          Estimated probabilities.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Project data to maximize class separation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_components) or             (n_samples, min(rank, n_components))\n",
      " |          Transformed data. In the case of the 'svd' solver, the shape\n",
      " |          is (n_samples, min(rank, n_components)).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base._ClassNamePrefixFeaturesOutMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Only used to validate feature names with the names seen in :meth:`fit`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base._ClassNamePrefixFeaturesOutMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the predictions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Vector containing the class labels for each sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbac7265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 369), (800, 1))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_train_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9350660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=368)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=368)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=368)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA\n",
    "pca=PCA(n_components=len(X_train.columns)-1)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf5c313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca=pca.fit_transform(X_train)\n",
    "X_test_pca=pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5484232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 368), (200, 368))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape,X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be5c79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO & RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76338eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prave\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=LogisticRegression(), max_features=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=LogisticRegression(), max_features=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(), max_features=10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sel=SelectFromModel(LogisticRegression(penalty='l2'),max_features=10)\n",
    "sel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9bead09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d211b12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_var5_0',\n",
       " 'num_var5',\n",
       " 'num_var8_0',\n",
       " 'num_var30',\n",
       " 'num_var22_ult1',\n",
       " 'num_meses_var39_vig_ult3',\n",
       " 'num_op_var41_efect_ult1',\n",
       " 'num_op_var39_efect_ult1',\n",
       " 'num_var43_recib_ult1',\n",
       " 'num_trasp_var11_ult1']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features=X_train.columns[sel.get_support()].to_list() #Selected columns\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0265e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_l2=X_train[selected_features]\n",
    "X_test_l2=sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93b3bbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;),\n",
       "                max_features=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;),\n",
       "                max_features=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(penalty='l1', solver='liblinear'),\n",
       "                max_features=10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel=SelectFromModel(LogisticRegression(penalty='l1',solver='liblinear'),max_features=10)\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "491fddc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_var5', 'num_var8_0', 'num_var30_0', 'num_var30', 'num_var42_0',\n",
       "       'num_var22_ult1', 'num_meses_var39_vig_ult3', 'num_op_var41_efect_ult1',\n",
       "       'num_op_var39_efect_ult1', 'num_trasp_var11_ult1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58eb75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_l1=X_train.columns[sel.get_support()]\n",
    "x_test_l1=sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5b0aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECURSIVE FEATURE ELIMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "196c36df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=RandomForestClassifier(n_estimators=10, n_jobs=-1),\n",
       "    n_features_to_select=10, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=RandomForestClassifier(n_estimators=10, n_jobs=-1),\n",
       "    n_features_to_select=10, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=RandomForestClassifier(n_estimators=10, n_jobs=-1),\n",
       "    n_features_to_select=10, verbose=2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe=RFE(RandomForestClassifier(n_estimators=10,n_jobs=-1),\n",
    "   n_features_to_select=10, verbose=2).fit(X_train,y_train)\n",
    "rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8762c013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var15', 'saldo_var30', 'saldo_var42', 'num_var22_ult3',\n",
       "       'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3',\n",
       "       'saldo_medio_var5_ult1', 'saldo_medio_var5_ult3', 'var38'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da8f5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe=X_train.columns[rfe.get_support()]\n",
    "X_test_rfe=rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2604c374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae4bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
